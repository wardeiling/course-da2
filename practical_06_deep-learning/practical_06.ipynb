{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1 Introduction\n",
        "\n",
        "In this practical, we will create a feed-forward neural network as well as a convolutional neural network to analyze the famous MNIST dataset.\n",
        "\n",
        "Let's first set up the libraries"
      ],
      "metadata": {
        "id": "D185Z_jqat_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install tensorflow matplotlib numpy\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, Dropout\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3DH1k-ca4gF",
        "outputId": "c3624101-cf16-46f5-b501-e55f655c5060"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.12.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.69.0)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 Take-home exercises: deep feed-forward neural network\n",
        "\n",
        "In this section, we will develop a deep feed-forward neural network for MNIST.\n",
        "\n",
        "## 2.1 Data preparation\n",
        "\n",
        "**1. Load the built-in MNIST dataset by running the following code. Then, describe the structure and contents of the `mnist` object.**\n",
        "\n",
        "Plotting is very important when working with image data. We have defined a convenient plotting function for you.\n",
        "\n",
        "**2. Use the `plot_img()` function below to plot the first training image. The `img` parameter has to be a matrix with dimensions `(28, 28)`.** NB: indexing in 3-dimensional arrays works the same as indexing in matrices, but you need an extra comma `x[,,]`.\n",
        "\n",
        "```{r}\n",
        "plot_img <- function(img, col = gray.colors(255, start = 1, end = 0), ...) {\n",
        "  image(t(img), asp = 1, ylim = c(1.1, -0.1), col = col, bty = \"n\", axes = FALSE, ...)\n",
        "}\n",
        "```\n",
        "\n",
        "It is usually a good idea to normalize your features to have a manageable, standard range before entering them in neural networks.\n",
        "\n",
        "**3. As a preprocessing step, ensure the brightness values of the images in the training and test set are in the range (0, 1)**\n"
      ],
      "metadata": {
        "id": "NV-v0xkjbgO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the MNIST dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to range (0, 1)\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S22lr7IkbkYQ",
        "outputId": "3db46fb4-1ad5-4026-d1cc-068b1836788c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to plot an image\n",
        "def plot_img(img):\n",
        "    plt.imshow(img, cmap=\"gray\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "plot_img(x_train[0])  # Plot the first training image\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "KqipavI8bvd-",
        "outputId": "9a02511a-5799-483c-b0ba-6b44ecfaa2d8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Multinomial logistic regression\n",
        "\n",
        "The simplest model is a multinomial logistic regression model, where we have no hidden layers and 10 outputs (0-1). That model is shown below.\n",
        "\n",
        "**4. Display a summary of the multinomial model using the `summary()` function. Describe why this model has 7850 parameters.**\n",
        "\n",
        "```{r}\n",
        "multinom  <-\n",
        "  keras_model_sequential(input_shape = c(28, 28)) %>% # initialize a sequential model\n",
        "  layer_flatten() %>% # flatten 28*28 matrix into single vector\n",
        "  layer_dense(10, activation = \"softmax\") # softmax outcome == logistic regression for each of 10 outputs\n",
        "\n",
        "multinom$compile(\n",
        "  loss = \"sparse_categorical_crossentropy\", # loss function for multinomial outcome\n",
        "  optimizer = \"adam\", # we use this optimizer because it works well\n",
        "  metrics = list(\"accuracy\") # we want to know training accuracy in the end\n",
        ")\n",
        "```\n",
        "\n",
        "**5. Train the model for 5 epochs using the code below. What accuracy do we obtain in the validation set?** (NB: the multinom object is changed “in-place”, which means you don’t have to assign it to another variable)\n",
        "\n",
        "```{r}\n",
        "multinom %>% fit(x = mnist$train$x, y = mnist$train$y, epochs = 5, validation_split = 0.2, verbose = 1)\n",
        "```\n",
        "\n",
        "**6. Train the model for another 5 epochs. What accuracy do we obtain in the validation set?**\n"
      ],
      "metadata": {
        "id": "jUzAk_6UbpmW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a multinomial logistic regression model\n",
        "multinom = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "multinom.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=\"adam\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history_multinom = multinom.fit(\n",
        "    x_train, y_train, epochs=5, validation_split=0.2, verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ze6KWrfXbtjY",
        "outputId": "575e2eea-4ba9-4a6c-d54b-4f7958124c33"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8044 - loss: 0.7679 - val_accuracy: 0.9112 - val_loss: 0.3198\n",
            "Epoch 2/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9104 - loss: 0.3230 - val_accuracy: 0.9227 - val_loss: 0.2848\n",
            "Epoch 3/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9188 - loss: 0.2923 - val_accuracy: 0.9220 - val_loss: 0.2768\n",
            "Epoch 4/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9213 - loss: 0.2817 - val_accuracy: 0.9247 - val_loss: 0.2694\n",
            "Epoch 5/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9246 - loss: 0.2722 - val_accuracy: 0.9258 - val_loss: 0.2708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We obtain an accuracy of 0.926 for the validation set."
      ],
      "metadata": {
        "id": "Y9Ki7ghkhE0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train for another 5 epochs\n",
        "history_multinom = multinom.fit(\n",
        "    x_train, y_train, epochs=5, validation_split=0.2, verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_4SeTM2bzSN",
        "outputId": "9da4a486-82fd-45fb-d055-6696fe96522f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9244 - loss: 0.2654 - val_accuracy: 0.9273 - val_loss: 0.2635\n",
            "Epoch 2/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9272 - loss: 0.2631 - val_accuracy: 0.9291 - val_loss: 0.2633\n",
            "Epoch 3/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9263 - loss: 0.2571 - val_accuracy: 0.9285 - val_loss: 0.2638\n",
            "Epoch 4/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9302 - loss: 0.2556 - val_accuracy: 0.9298 - val_loss: 0.2596\n",
            "Epoch 5/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9299 - loss: 0.2551 - val_accuracy: 0.9297 - val_loss: 0.2620\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After training for 5 more Epoch's, the accuracy for the validation set rises to 0.930, so an improvement of 0.004 over the initial model."
      ],
      "metadata": {
        "id": "GZl_UDOnhLii"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 Deep feed-forward neural networks.\n",
        "\n",
        "**7. Create and compile a feed-forward neural network with the following properties. Ensure that the model has 50890 parameters.**\n",
        "\n",
        "-   sequential model\n",
        "\n",
        "-   flatten layer\n",
        "\n",
        "-   dense layer with 64 hidden units and “relu” activation function\n",
        "\n",
        "-   dense output layer with 10 units and softmax activation function\n",
        "\n",
        "You may reuse code from the multinomial model\n",
        "\n",
        "**7. Train the model for 10 epochs. What do you see in terms of validation accuracy, also compared to the multinomial model?**\n",
        "\n",
        "**8. Create predictions for the test data using the two trained models (using the function below). Create a confusion matrix and compute test accuracy for these two models. Write down any observations you have.**\n",
        "\n",
        "```{r}\n",
        "class_predict <- function(model, x_train) predict(model, x = x_train) %>% apply(1, which.max) - 1\n",
        "```\n",
        "\n",
        "**9. OPTIONAL: if you have time, create and estimate (10 epochs) a deep feed-forward model with the following properties. Compare this model to the previous models on the test data.**\n",
        "\n",
        "-   sequential model\n",
        "\n",
        "-   flatten layer\n",
        "\n",
        "-   dense layer with 128 hidden units and “relu” activation function\n",
        "\n",
        "-   dense layer with 64 hidden units and “relu” activation function\n",
        "\n",
        "-   dense output layer with 10 units and softmax activation function"
      ],
      "metadata": {
        "id": "hOr0eriCby0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a feed-forward neural network\n",
        "dnn = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(64, activation=\"relu\"),\n",
        "    Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "dnn.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=\"adam\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history_dnn = dnn.fit(\n",
        "    x_train, y_train, epochs=10, validation_split=0.2, verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2l84ibcb6ue",
        "outputId": "407b46f6-fc79-4e79-ac69-1eef67175658"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8504 - loss: 0.5369 - val_accuracy: 0.9467 - val_loss: 0.1947\n",
            "Epoch 2/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9487 - loss: 0.1806 - val_accuracy: 0.9569 - val_loss: 0.1477\n",
            "Epoch 3/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9652 - loss: 0.1221 - val_accuracy: 0.9645 - val_loss: 0.1216\n",
            "Epoch 4/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9708 - loss: 0.0997 - val_accuracy: 0.9651 - val_loss: 0.1177\n",
            "Epoch 5/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9752 - loss: 0.0828 - val_accuracy: 0.9703 - val_loss: 0.1051\n",
            "Epoch 6/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9809 - loss: 0.0641 - val_accuracy: 0.9716 - val_loss: 0.0980\n",
            "Epoch 7/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9852 - loss: 0.0530 - val_accuracy: 0.9662 - val_loss: 0.1162\n",
            "Epoch 8/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9858 - loss: 0.0466 - val_accuracy: 0.9714 - val_loss: 0.1027\n",
            "Epoch 9/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9884 - loss: 0.0384 - val_accuracy: 0.9710 - val_loss: 0.1013\n",
            "Epoch 10/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9917 - loss: 0.0310 - val_accuracy: 0.9734 - val_loss: 0.1024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to predict classes\n",
        "def class_predict(model, x_data):\n",
        "    return np.argmax(model.predict(x_data), axis=1)\n",
        "\n",
        "# Generate predictions and confusion matrix\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "y_pred_multinom = class_predict(multinom, x_test)\n",
        "y_pred_dnn = class_predict(dnn, x_test)\n",
        "\n",
        "confusion_multinom = confusion_matrix(y_test, y_pred_multinom)\n",
        "confusion_dnn = confusion_matrix(y_test, y_pred_dnn)\n",
        "\n",
        "print(\"Multinomial Accuracy:\", accuracy_score(y_test, y_pred_multinom))\n",
        "print(\"DNN Accuracy:\", accuracy_score(y_test, y_pred_dnn))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qhj_PXGib8Gu",
        "outputId": "4d927751-9788-4b26-cbba-c9fe1edde70d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Multinomial Accuracy: 0.9252\n",
            "DNN Accuracy: 0.9718\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The multinomial accuracy is 0.925, while the DNN accuracy is 0.972. Thus, the accuracy of the deep-forward neural network is superior to that of the multinomial logistic regression."
      ],
      "metadata": {
        "id": "KfpdSDCIfK3y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 Lab exercises: convolutional neural network\n",
        "\n",
        "Convolution layers in Keras need a specific form of data input. For each example, they need a `(width, height, channels)` array (tensor). For a colour image with 28\\*28 dimension, that shape is usually `(28, 28, 3)`, where the channels indicate red, green, and blue. MNIST has no colour info, but we still need the channel dimension to enter the data into a convolution layer with shape `(28, 28, 1)`. The training dataset `x_train` should thus have shape `(60000, 28, 28, 1)`.\n",
        "\n",
        "**10. add a “channel” dimension to the training and test data using the following code. Plot an image using the first channel of the 314th training example (this is a 9).**\n",
        "\n",
        "```{r}\n",
        "# add channel dimension to input (required for convolution layers)\n",
        "dim(mnist$train$x) <- c(dim(mnist$train$x), 1)\n",
        "dim(mnist$test$x)  <- c(dim(mnist$test$x), 1)\n",
        "```\n",
        "\n",
        "**11. Create and compile a convolutional neural network using the following code. Describe the different layers in your own words.**\n",
        "\n",
        "```{r}\n",
        "cnn <-\n",
        "  keras_model_sequential(input_shape = c(28, 28, 1)) %>%\n",
        "  layer_conv_2d(filters = 6, kernel_size = c(5, 5)) %>%\n",
        "  layer_max_pooling_2d(pool_size = c(4, 4)) %>%\n",
        "  layer_flatten() %>%\n",
        "  layer_dense(units = 32, activation = \"relu\") %>%\n",
        "  layer_dense(10, activation = \"softmax\")\n",
        "\n",
        "cnn %>%\n",
        "  compile(\n",
        "    loss = \"sparse_categorical_crossentropy\",\n",
        "    optimizer = \"adam\",\n",
        "    metrics = c(\"accuracy\")\n",
        "  )\n",
        "```\n",
        "\n",
        "**12. Fit this model on the training data (10 epochs) and compare it to the previous models.**\n",
        "\n",
        "**13. Create another CNN which has better validation performance within 10 epochs. Compare your validation accuracy to that of your peers.**\n",
        "\n",
        "Here are some things you could do:\n",
        "\n",
        "-   Reduce the convolution filter size & the pooling size and add a second convolutional & pooling layer with double the number of filters\n",
        "\n",
        "-   Add a dropout layer after the flatten layer\n",
        "\n",
        "-   Look up on the internet what works well and implement it!"
      ],
      "metadata": {
        "id": "uCUjcIPAb9qt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape data to include channel dimension\n",
        "x_train = x_train[..., np.newaxis]\n",
        "x_test = x_test[..., np.newaxis]\n",
        "\n",
        "# Verify the shape\n",
        "print(x_train.shape, x_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yb98FzgocDF0",
        "outputId": "99e42a5b-769c-4fd0-bad2-ca69ce4f49f9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28, 1) (10000, 28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a CNN\n",
        "cnn = Sequential([\n",
        "    Conv2D(6, kernel_size=(5, 5), activation=\"relu\", input_shape=(28, 28, 1)),\n",
        "    MaxPooling2D(pool_size=(4, 4)),\n",
        "    Flatten(),\n",
        "    Dense(32, activation=\"relu\"),\n",
        "    Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "cnn.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=\"adam\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history_cnn = cnn.fit(\n",
        "    x_train, y_train, epochs=10, validation_split=0.2, verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYO666YecEon",
        "outputId": "232381d7-36a0-41bf-e0e7-1753d98196d9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.7677 - loss: 0.7597 - val_accuracy: 0.9533 - val_loss: 0.1557\n",
            "Epoch 2/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 15ms/step - accuracy: 0.9547 - loss: 0.1477 - val_accuracy: 0.9647 - val_loss: 0.1180\n",
            "Epoch 3/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 16ms/step - accuracy: 0.9686 - loss: 0.1022 - val_accuracy: 0.9711 - val_loss: 0.0908\n",
            "Epoch 4/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 18ms/step - accuracy: 0.9746 - loss: 0.0829 - val_accuracy: 0.9764 - val_loss: 0.0777\n",
            "Epoch 5/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 16ms/step - accuracy: 0.9773 - loss: 0.0716 - val_accuracy: 0.9800 - val_loss: 0.0699\n",
            "Epoch 6/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 16ms/step - accuracy: 0.9783 - loss: 0.0699 - val_accuracy: 0.9796 - val_loss: 0.0671\n",
            "Epoch 7/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.9813 - loss: 0.0607 - val_accuracy: 0.9808 - val_loss: 0.0676\n",
            "Epoch 8/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.9846 - loss: 0.0491 - val_accuracy: 0.9790 - val_loss: 0.0706\n",
            "Epoch 9/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.9840 - loss: 0.0473 - val_accuracy: 0.9796 - val_loss: 0.0651\n",
            "Epoch 10/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.9852 - loss: 0.0467 - val_accuracy: 0.9826 - val_loss: 0.0588\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After 10 Epoch's the accuracy is 0.985 and the validation accuracy is 0.983, both of which are very high."
      ],
      "metadata": {
        "id": "rdWZrnNagBNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a more complex CNN\n",
        "cnn_custom = Sequential([\n",
        "    Conv2D(16, kernel_size=(3, 3), activation=\"relu\", input_shape=(28, 28, 1)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Flatten(),\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation=\"relu\"),\n",
        "    Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "cnn_custom.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=\"adam\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history_cnn_custom = cnn_custom.fit(\n",
        "    x_train, y_train, epochs=10, validation_split=0.2, verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qsn03x_PcF3y",
        "outputId": "cde4d5d0-54f0-4499-8669-705496651446"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 23ms/step - accuracy: 0.8266 - loss: 0.5478 - val_accuracy: 0.9783 - val_loss: 0.0713\n",
            "Epoch 2/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 25ms/step - accuracy: 0.9638 - loss: 0.1171 - val_accuracy: 0.9833 - val_loss: 0.0569\n",
            "Epoch 3/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 19ms/step - accuracy: 0.9729 - loss: 0.0876 - val_accuracy: 0.9856 - val_loss: 0.0476\n",
            "Epoch 4/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.9765 - loss: 0.0727 - val_accuracy: 0.9878 - val_loss: 0.0413\n",
            "Epoch 5/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.9800 - loss: 0.0635 - val_accuracy: 0.9888 - val_loss: 0.0367\n",
            "Epoch 6/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.9829 - loss: 0.0562 - val_accuracy: 0.9891 - val_loss: 0.0374\n",
            "Epoch 7/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 25ms/step - accuracy: 0.9824 - loss: 0.0539 - val_accuracy: 0.9912 - val_loss: 0.0336\n",
            "Epoch 8/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 22ms/step - accuracy: 0.9858 - loss: 0.0456 - val_accuracy: 0.9897 - val_loss: 0.0343\n",
            "Epoch 9/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 22ms/step - accuracy: 0.9858 - loss: 0.0420 - val_accuracy: 0.9917 - val_loss: 0.0306\n",
            "Epoch 10/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 24ms/step - accuracy: 0.9869 - loss: 0.0394 - val_accuracy: 0.9909 - val_loss: 0.0325\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The accuracy of this improved CNN is 0.987, whereas the acccuracy on the validation set is even greater at 0.991."
      ],
      "metadata": {
        "id": "OWek8-2fg9CS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now evaluate the models"
      ],
      "metadata": {
        "id": "tPgcSUPTcIJ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate validation accuracy\n",
        "val_accuracy_cnn = history_cnn.history['val_accuracy'][-1]\n",
        "val_accuracy_cnn_custom = history_cnn_custom.history['val_accuracy'][-1]\n",
        "\n",
        "print(\"Validation Accuracy CNN:\", val_accuracy_cnn)\n",
        "print(\"Validation Accuracy Custom CNN:\", val_accuracy_cnn_custom)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gI5KEL7cKMT",
        "outputId": "2037efc8-731b-429e-b952-433a6f6a8de0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy CNN: 0.9825833439826965\n",
            "Validation Accuracy Custom CNN: 0.9909166693687439\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unsurprisingly, the improved CNN model has an improved validation accuracy with a difference of 0.008 to an impressive 0.991."
      ],
      "metadata": {
        "id": "5Uk45L1Uh58N"
      }
    }
  ]
}